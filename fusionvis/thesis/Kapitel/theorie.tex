%----------------------------------------------------------------%
% theorie.tex																			       %
%----------------------------------------------------------------%

\chapter{Multisensorische Daten und ihre Visualisierung}
\label{ch:theorie}

In diesem Kapitel soll zuerst der Zusammenhang zwischen dem Thema dieser Arbeit und den dafür relevanten theoretischen Grundlagen dargelegt werden. Darauf folgend sollen Möglichkeiten der Datenvisualisierung aufgezeigt. Einige davon sind in der prototypischen Implementierung umgesetzt, andere wurden nicht aufgenommen. Die Gründe dafür sollen an geeigneter Stelle dargelegt werden.

\section{Theoretische Einordnung}
\label{sec:TheoretischeEinordnung}
In diesem Abschnitt soll die  theoretische Einordnung der Arbeit erfolgen. An erster Stelle steht dabei die Erläuterung multisensorischer Daten anhand eines einfachen Beispiels. Anschließend soll mit dessen Hilfe der Begriff \emph{Multisensor Data Fusion} definiert und der praktische Teil dieser Arbeit in den theoretischen Kontext eingeordnet werden.

\subsection{Multisensorische Daten}
\label{sec:EigenschaftenVonMultisensorischenDaten}
Der Begriff der \emph{multisensorischen Daten} existiert in der Literatur nicht losgelöst. Interessant ist er nur in Verbindung der Fusion von Daten. Trotzdem soll an dieser Stelle eine kurze begriffliche Betrachtung stehen.

\label{beispiel}
Ein kleines Beispiel verdeutlicht sehr gut, worum es hier geht: Man stelle sich einen Tisch vor, auf dem zwei brennende Kerzen stehen. Davor befinden sich drei Beobachter. Jeder soll unabhängig von den anderen jeden Gegenstand, den er sieht, auf je einem Blatt Papier beschreiben. Bei den entstehenden Dokumenten handelt es sich um eine Form von multisensorischen Daten. Ein Datum ist dabei eine Beschreibung eines Gegenstandes. Ein Sensor ist jeweils einer der Beobachter.  Dies ist ein Ansatz, sich der Thematik zu nähern. 

Ein anderer Ansatz könnte bei selbem Aufbau mit einer Person gemacht werden. Denn der Mensch, oder besser seine Sinne liefert schon multisensorische Daten. Die Person sieht eine Lichtquelle und fühlt eine Hitzequelle. Diese beiden Beobachtungen sind die Daten, die Sensoren sind Tastsinn und Sehsinn.

Multisensorische Daten wie oben geschildert sind aber in der Theorie und Praxis nicht von Bedeutung, wenn sie für sich genommen werden. Schlüssige Informationen daraus sind nämlich nicht möglich, ohne die Eingangsdaten zu interpretieren. Dieser Vorgang, man spricht von \emph{Multisensor Data Fusion}, soll in Abschnitt \ref{sec:MultisensorFusion} erläutert werden.
\paragraph{Vorteile}
\label{sec:Vorteile}
In \cite{MDFLLINAS} werden neun Vorteile von multisensorischen Systemen (und den von ihnen gelieferten Daten) aufgezählt, die hier in Auswahl sinngemäß wiedergegeben werden sollen:

\begin{enumerate}
	\item \textbf{Robustheit:} Informationen können weiter gesammelt werden, auch wenn ein oder mehrere Sensoren keine Daten mehr liefern.

	\item \textbf{R\protect\"aumlich weitreichende Abdeckung:} Daten, die vielleicht nur von einem ein paar Sensoren gesehen werden, würden nicht entdeckt, wenn nur ein einzelner Sensor an der falschen Stelle steht.

	\item \textbf{Zeitlich weitreichende Abdeckung:} Nicht jeder Sensor steht zu jeder Zeit zur Verfügung. Bei zeitlichem Versatz und Überlappung kann eine dauerhafte Datensammlung betrieben werden.

	\item \textbf{Gesteigerte Informationssicherheit:} Wird ein Datum durch mehrere Sensoren erfasst, verringert sich die Wahrscheinlichkeit eines Messfehlers.

	\item \textbf{Erhöhte Informationsdichte:} Die Auflösung, mit der mehrer Sensoren ein Gebiet abtasten können, ist höher als die Auflösung eines einzelnen Sensors.
\end{enumerate}

Diese Reihe von Vorteilen zeigt, dass die Datensammlung mit mehreren Sensoren durchaus betrieben werden sollte. Die entstehenden Daten bieten vor allem durch ihre Redundanzen  mehr und sichere Informationen als die eines einzelnen Sensors.

\paragraph{Nachteile}
\label{sec:Nachteile}
Die oben angesprochene Redundanz ist zugleich der größte Nachteil von multisensorischen Daten. Wie sich das äußert, sei noch mal an dem in Abschnitt \ref{beispiel} eingeführten Beispiel erläutert: Die schriftlich gesammelten Daten der drei Beobachter werden an eine Person weitergegeben, die sich zum Zeitpunkt der Beobachtungen an einem anderen Ort aufhielt. Diese Person soll aus den Daten schließen, was sich auf dem Tisch befand. Sie hat dabei keine Informationen, welche Daten von welchem Beobachter stammen. Ebenfalls ist unbekannt, wie viele Beobachter überhaupt beteiligt waren.

Aus den Daten könnte die auswertende Person schließen, dass sechs Kerzen auf dem Tisch befanden. Dies ist ein völlig falsches Bild und der Grund für die Fehlinterpretation ist die Redundanz der Daten, die nicht beseitigt wurde. Nur wenn Datensätze, die zu einem realen Objekt gehören, zusammengeführt werden, kann man die Vorteile von multisensorischen Daten nutzen.


 
\subsection{Multisensor Data Fusion}
\label{sec:MultisensorFusion}
Um die Redundanz aus den von mehreren Sensoren gewonnenen Daten herauszufiltern, müssen die Datensätze fusioniert werden. Die theoretischen Hintergründe zu dem \emph{Multisensor Data Fusion} genannten Vorgang sind im Folgenden dargelegt. 
\paragraph{Begriffsbestimmung}
\label{sec:Begriffsbestimmung}
Der Begriff \emph{Fusion} kann wie folgt definiert werden:
\begin{quote}
		"`[Fusion is] the integration of information from multiple sources to procedure specific and comprehensive unified data about an entity"' \protect\cite{fusionintroduction}
\end{quote}


Aus dieser Definition kann geschlossen werden, dass durch die Fusion von Daten nicht nur ungewollte Redundanzen beseitigt werden können. Es wird auch ein Informationsgewinn erreicht, der auf den Vorteilen mehrerer Sensoren beruht (siehe \ref{sec:Vorteile}), frei nach Aristoteles: "`Das Ganze ist mehr als die Summe seiner Teile."'. Datenfusion ist ein Prozess, der nach \cite{MDFLLINAS} drei Aspekte in sich vereint:

\begin{itemize}
	\item Datenfusion ist ein Prozess, der auf Unterschiedlichen Ebenen Abläuft. Die unterschiedlichen \emph{Level} beziehen sich auf den unterschiedlich hohen Abstraktionsgrad der Daten. Sie sind im nächsten Abschnitt beschrieben.

	\item Datenfusion schließt die Vorgänge der Erkennung, Assoziation, Korrelation, Beurteilung und Vereinigung von Daten ein.

	\item Das Ergebnis des Prozesses umfasst Anschätzung zu Identifikation und Eigenschaften von Daten bis hin zu Erkenntnissen über komplexe Lagen oder Situationen.
\end{itemize}

Datenfusion findet in vielen Breichen, vor allem beim Militär, Anwendung. Beispiele werden in \cite{mathfusion} aufgezeigt. Dazu gehören unter anderem die Überwachung der Meere, Luftverteidigung (durch Boden- und durch Lufteinheiten), Aufklärung auf dem Gefechtsfeld, strategische Luftaufklärung, Suche nach Bodenschätzen, Diagnostik in der Medizin und vor allem Robotik. 

\paragraph{Fusion Level}
\label{sec:FusionLevel}

Die Datenfusion kann, wie oben bereits angesprochen, in insgesamt fünf unterschiedliche Ebenen unterteilt werden. Grundlage dafür ist das vom Joint Directors of Laboratories (JDL) entwickelte Prozessmodell (\cite{mathfusion}). Der Abstraktionsgrad erhöht sich mit aufsteigender Stufennummer. Für die praktische Anwendung von Datenfusion sind vor allem die ersten drei Stufen relevant.

\begin{itemize}
	\item Level 1 -- Object Assessment: Bestimmung der Identität und der Eigenschaften eines Objekts

	\item Level 2 -- Situation Assessment: Bewertung einer Lage einschließlich der Bestimmung von Beziehungen zwischen Objekten, zwischen den Objekten und ihrer Umgebung und ihrer Bedeutung.

	\item Level 3 -- Impact Assessment: Entwicklung der gegenwärtigen Lage in die Zukunft und damit verbundene Auswirkungen (zum Beispiel Bedrohungen)
\end{itemize}

Die in dieser Arbeit umgesetzte Fusion durch Visualisierung soll im nächsten Abschnitt in dieses Modell eingeordnet werden.


\paragraph{Einordnung der Arbeit}
\label{sec:EinordnungDerArbeit}

Der Sachverhalt des S2-Offiziers, der Meldungen aus dem Gefechtsfeld bekommt, und diese zu einer großen Lage zusammenfügt könnte sehr einfach in die zweite Ebene eingeordnet werden, schließlich erstellt er eine Lage. Diese Einschätzung ist jedoch falsch, denn um auf dieses Level zu kommen, muss die Redundanz in den Objekten beseitigt sein, und genau das ist schließlich erst das Ziel. Dies ist das erste Problem bei der Einordnung.

Ein weiteres Problem entsteht durch die Sensoren, welche die Daten für die Visualisierung und damit für die Fusion liefern. Es handelt sich (in der Realität im Gegensatz zum Gefechtssimulator)  entweder um Menschen, oder Computer, die sich in militärischen Fahrzeugen befinden. Wenn diese zum Beispiel ein gegnerisches Fahrzeug erkannt haben und dieses Melden, ist bis dahin bereits Datenfusion geschehen. Der jeweilige Mensch (oder Computer) hat Daten gesammelt und zu einer Meldung eines Objekts fusioniert. Da hier eine Identifikation und eine Bestimmung der Eigenschaften vorgenommen wurden, handelt es sich bei diesem Vorgang um Level 1 Fusion.

 Diese Daten werden nun an den S2-Offizier übermittelt. An dieser Stelle würde nach dem JDL Prozess ein System die Daten, die ermittelt wurden, zusammenführen. Ziel dieser Arbeit war jedoch, diesen Schritt durch Visualisierung vom S2-Offizier selbst durchführen zu lassen.

An dieser Stelle entsteht ein Bruch zwischen dem JDL Prozess und dem hier verfolgten Ansatz. Im ursprünglichen Prozess ist die erste große Hürde, die Daten der unterschiedlichsten Sensoren (Radar, visuell Sensoren, Infrarot, Schall) zu korrelieren. Nachdem der Schritt geschafft ist, ist die Verwaltung unterschiedlicher Meldungen nur noch eine Nebensache. In dieser Arbeit wird aber genau dieser Aspekt in den Vordergrund gerückt. 

Weil der S2-Offizier mit der Aufgabe betraut ist, die Redundanzen zu beseitigen und das erzeugen einer Lage vorzubereiten, ist die visuelle Fusion immer noch auf der ersten Ebene. Der nächste Schritt ist darauf folgend die Aggregation von Daten, in diesem Fall das zusammenfassen von einzelnen gegnerischen Panzern zu Zügen, diese zu Kompanien usw.

\section{Visualisierungsmöglichkeiten}
\label{sec:Visualisierungsmoeglichkeiten}
Im Gegensatz zur in \cite{fusionintroduction} definierten Datenfusion soll die Beseitigung von Redundanzen in dem implementierten Prototyp durch eine geschickte Visualisierung der Daten erfolgen. Beispiele dafür werden im Folgenden erläutert. Einige finden sich in der Implementierung wieder, manche können noch ergänzt werden. An manchen Stellen musste aber eine klare Abwägung getroffen werden. Konsequenz war, dass sich bestimmte Visualisierungsarten nicht oder nur bedingt eignen.
 
\subsection{Darstellung der Dimensionen}
\label{sec:DarstellungDerDimensionen}
 Eine wichtige Entscheidung bei der Visualisierung von Daten ist, in wie vielen Dimensionen die Daten dargestellt werden sollen. Ist dies festgelegt, stellt sich die Frage, welche Eigenschaft der Daten auf welche Dimension abgebildet werden soll. 
 
\subsubsection{Dreidimensionale Darstellung}
\label{sec:DreidimensionaleDarstellung}
Ziel der praktischen Arbeit ist die dreidimensionale Darstellung von Datensätzen aus einem Gefechtssimulator. Diese Art der Datenanzeige bietet die höchste Flexibilität, jedoch kommet man bei der Abbildung von Eigenschaften auf Dimensionen zu einem Problem: Datensätze, die reale Gegenstände beschreiben, haben meistens mehr als drei Eigenschaften, die sich für ihre Positionierung eignen. Im Allgemeinen wird der Ort eines Datums durch drei Koordinaten im Raum festgelegt. Zusätzlich gibt es bei Datensätzen, die eine Sichtung beschrieben, eine Zeitangabe. Diese beschreibt, wann die Sichtung stattgefunden hat. Für die dreidimensionale Darstellung müssen drei der vier ausgewählt werden.

\paragraph{Länge-Breite-Höhe}
\label{sec:LaengeBreiteHoehe}

Eine mögliche Alternative ist die Vernachlässigung der Zeit. Diese Auswahl ist für das gestellte Problem nicht zielführend, denn durch die fehlende Zeitkomponente können Redundanzen nicht erkannt werden. Sie werden sogar gefördert. Zwei Objekte zu zwei unterschiedlichen Zeiten könnten als vier Objekte interpretiert werden. Genau diese Tatsache sollte verhindert werden. Aus diesem Grund ist diese Auswahl nicht geeignet.

\paragraph{Länge-Breite-Zeit}
\label{sec:LaengeBreiteZeit}

Die andere mögliche Alternative ist die Vernachlässigung der Höhe als Positionsangabe. Zugunsten dieser kann dann die Zeit dargestellt werden. Auch hier gibt es einen Informationsverlust. Die Auswirkungen werden in Abschnitt \ref{ch:kugelkappe} beschrieben. Für das Beseitigen von Redundanzen fällt das Weglassen der Höhe im Falle eines Gefechtssimulators nur beschränkt ins Gewicht. Landeinheiten befinden sich selten übereinander, dadurch können keine zusätzlichen Redundanzen entstehen.

Die Darstellung der Zeit als dritte Dimension (in die Höhe) bietet zwei klare Vorteile. Auf der einen Seite können in einer großen dreidimensionalen Visualisierung die unterschiedlichen Momentaufnahmen einer Lage dargestellt werden. Es ist somit eine Visuelle Lageentwicklung aus einem statischen Bild ablesbar. Auf der anderen Seite kann die Bewegungsreichweite einer Einheit anhand ihrer Maximalgeschwindigkeit veranschaulicht werden. Wie das dargestellt werden kann, wird in Abschnitt \ref{sec:TheorieBewegungskegel}, \ref{sec:Bewegungskegel} und \ref{ch:bewegungskegel} erläutert.


\subsubsection{Vierdimensionale Darstellung}
\label{sec:VierdimensionaleDarstellung}
Die beiden im letzten Abschnitt aufgezeigten Auswahlmöglichkeiten für eine dreidimensionale Visualisierung haben beide den Nachteil, dass man einen Informationsverlust in Kauf nehmen muss. Eine Möglichkeit dies zu vermeiden, wäre eine vierdimensionale Darstellung. Auf der einen Seite ist die menschliche Vorstellungskraft nicht unbedingt in der Lage, eine solche Visualisierung zu verstehen. Auf der anderen Seite benötigt man schon für die dreidimensionale Darstellung mindestens eine zweidimensionale Projektionsfläche. Für die vierte Dimension müsste man mindestens eine echte 3D-Darstellung haben, dies ist ohne spezielle Technik nicht möglich und entfällt darum.

Es gibt aber dennoch eine Variante, alle drei Lageinformationen (Länge, Breite und Höhe), sowie die Zeit darzustellen. Dazu werden zuerst die drei Dimensionen für die genaue Umsetzung der Position genutzt. Danach wird die Zeit visualisiert. Eine sehr einfache und eingängige Art ist die Nutzung von Transparenz. Die neusten Informationen werden dann völlig undurchsichtig angezeigt. Mit dem Alter wird die Transparenz erhöht. Auf diese Weise können alle vier Informationen dargestellt werden. Problematisch ist nur, dass die Möglichkeit einer Reichweitenanalyse durch Visualisierung ungemein schwerer, wenn nicht sogar unmöglich wird. Statt dem Kegel müsste eine Kugel dargestellt werden, die im Zentrum nicht sichtbar ist und deren Transparenz nach außen kontinuierlich nachlässt, so dass sie auf ihrer Oberfläche undurchsichtig ist. Um festzustellen, ob zwei Objekte zueinander gehören, müsste man ihren Transparenzgrad vergleichen. Für kleine Zeitunterschiede ist dies aber nicht machbar. Aus diesem Grund ist eine vierdimensionale Visualisierung sicher ein interessanter Ansatz, der aber nur einen geringen Wert für die Lösung der Aufgabe hat.
\subsubsection{Niederdimensionale  Ansätze}
\label{sec:NiederdimensionaleAnsaetze}
Für die Problemstellung dieser Arbeit sicher nicht zielführend, aber dennoch zu betrachten sind niederdimensionale Ansätze. Unzweckmäßig sind sie, weil schon bei einer dreidimensionalen Darstellung von Gefechtssimulatordaten Informationen verloren gehen. Es gibt aber Fragestellungen, bei denen sie vielleicht eine Rolle spielen könnten. Auch gibt es anders geartete Probleme, bei denen weniger zu visualisierende Eigenschaften vorliegen, so dass eine ein- oder zweidimensionale Darstellung ausreicht.

\paragraph{Zwei Dimensionen}
\label{sec:ZweiDimensionen}

Eine mögliche Anwendung für diese Ansicht ist die Vernachlässigung der Zeit, wenn die Frage zum Beispiel lautet, in welchem Raum treten die meisten Sichtungen auf. Dann reicht eine zweidimensionale Darstellung. 

Eine andere Anwendung ist die Frage nach der Lageentwicklung in Angriffsrichtung. Dabei kann die Breite des Gefechtsfelds vernachlässigt werden. Es interessiert nur, in welcher Zeit der Gegner mit wie vielen Einheiten vorstößt. 

\paragraph{Eine Dimension}
\label{sec:EineDimension}

Sicher gibt es sehr speziell geartete Fragestellungen, die eine Visualisierung von Daten auf einer Linie nötig machen. Man könnte zum Beispiel Datensätze aus einem Netzwerk darstellen. Wenn die Datensätze eine MAC-[ABK]Adresse umfassen, kann diese dazu benutzt werden, die Daten auf einer Linie anzuordnen. Dazu ist ein geeigneter Homomorphismus von dem Bereich der Adressen auf die reellen Zahlen notwendig. Ablesbar wäre dann zum Beispiel gehäuftes Auftreten von Handware eines bestimmten Herstellers.

Sowohl ein- als auch zweidimensionale Darstellung kann in bestimmten Anwendungsgebieten und bei machen Fragestellungen notwendig sein. Meistens lässt sich diese Art der Visualisierung aber auch durch geeignete Position der Kamera erreichen (siehe Abschnitt \ref{sec:VoreingestellteKameraperspektiven}).


\subsection{Darstellung der Datensätze}
\label{ch:visualisierungDatum}
Neben der Art und Weise wie Eigenschaften von Daten auf die Dimensionen übertragen werden können ist der nächste wichtige Aspekt der Visualisierung, wie ein Datensatz und seine Eigenschaften dargestellt werden.

\subsubsection{Formen}
\label{sec:Formen}
Unter der Form ist hier die geometrische Darstellung eines Datums zu verstehen. Dabei gibt es eine Vielzahl von Möglichkeiten, der Kreativität sind praktisch keine Grenzen gesetzt. Für den implementierten Prototyp haben sich Kugeln als zweckmäßig erwiesen. Sie haben den Vorteil, dass sie sehr einfach zu instanziieren, zugleich aber auch noch relativ anschaulich sind. Ihr Nachteil besteht in der Aufwendigkeit ihrer Darstellung. Da alle Objekte aus Polygonen konstruiert werden, ist eine Kugel nie ganz rund. Zwar kann die Anzahl an Polygonen, aus denen eine Kugel gefertigt wird, erhöht werden, aber das führt bei vielen Datensätzen zu erheblichen Ladezeiten.

Alternativ könnten Würfel oder Quader zur Visualisierung verwendet werden. Diese haben aber den Nachteil, dass sie ein falsches Bild vermitteln könnten, denn in der dreidimensionalen Darstellung sind die geometrischen Objekte nur die Visualisierung eines Datenpunkts und nicht ein echtes Objekt mit räumlichen Ausmaßen.

Dasselbe Problem, aber eine bessere Anschauung der angezeigten Daten hätte die Verwendung von vorgefertigten Modellen. So könnten für die Visualisierung von Panzern tatsächlich Panzer angezeigt werden. Die Erstellung der Modelle steht aber vom Aufwand her in keiner Relation zum Nutzen durch die verbesserte Anschauung des Problems.
[IMG]

\subsubsection{Visualisierung von Eigenschaften}
\label{sec:VisualisierungVonEigenschaften}
Damit die Visualisierung von Datensätzen wirklich nutzbringend ist, sollten möglichst viele seiner Eigenschaften auf den ersten Blick ersichtlich sein. Möglichkeiten dazu gibt es viele. Im Folgenden sollen einige aufgezeigt werden. Wichtig ist jedoch auch bei dem größten Informationsbedarf, dass die Übersichtlichkeit gewahrt bleiben muss. Weiterhin sollte bei der Wahl von Visualisierungsmitteln für Eigenschaften das Gesetz von Miller (aus \cite{miller7}) beachtet werden. Es besagt, dass das Kurzzeitgedächtnis nur 7$\pm$2 Informationen behalten kann. So sollten zum Beispiel nicht mehr als sieben Farben zu Visualisierung verwendet werden. 

\paragraph{Texturen}
\label{sec:theorieTexturen}

Texturen, wie in Abschnitt \ref{sec:Texturen} erläutert, dienen dazu Objekte farblich darzustellen. Sie sind besonders geeignet, Eigenschaften darzustellen, die nur eine endliche Menge an Werten annehmen können. So kann die Information, ob eine Einheit Freund oder Feind ist, sehr gut über einen Farbcode dargestellt werden. Üblicherweise bieten sich dafür die Farben blau für verbündete und eigene Kräfte, rot für Feinde und grün für neutrale Einheiten an. Ebenso lässt sich zum Beispiel die Darstellung der Art einer Meldung über Farben lösen. Die Umsetzung im Prototyp ist in Abschnitt \ref{sec:FarbigeDarstellungDerEigenschaften} beschrieben.

Um mehrere Eigenschaften über Farben zu visualisieren, kann die wichtigste Eigenschaft die Farbe bestimmen. Eine andere Eigenschaft kann die auf die Helligkeit, in der die Farbe angezeigt wird Einfluss nehmen.
[IMG]

\paragraph{Pfeile}
\label{sec:Pfeile}
 
Zur Visualisierung von vektoriellen Eigenschaften wie Blickrichtung (Eigenschaft ohne einen Betrag) oder Geschwindigkeit (Eigenschaft mit Betrag) können Pfeile verwendet werden, die entweder eine einheitliche Länge haben oder deren Länge dem Betrag der Größe entspricht, die Visualisiert werden soll.

\paragraph{Beschriftungen}
\label{sec:Beschriftungen}

Zur Darstellung von Eigenschaften können auch auf oder neben dem Datensatz eingeblendete Texte verwendet werden. Dieses Mittel eignet sich jedoch nicht besonders gut, da Zeit zum erfassen der Information relativ hoch ist, weil der Text gelesen werden muss. Auch wird die Visualisierung sehr schnell unübersichtlich.

\subsection{Informationsgewinnung durch Visualisierung}
\label{sec:InformationsgewinnungDurchVisualisierung}
Zusätzlich zum Erfassen von Daten durch den Benutzer kann die Visualisierung auch zur Informationsgewinnung beitragen. Möglich ist dies, indem die Daten ausgewertet werden und grafisch Zusatzinformationen eingeblendet werden. Diese ermöglichen weitere Schlüsse aus den Daten über die Daten. Als Beispiel soll hier die Reichweitenanalyse dienen. Sie wurde bereits in Abschnitt \ref{sec:LaengeBreiteZeit} angesprochen.

\subsubsection{Bewegungskegel}
\label{sec:TheorieBewegungskegel}
Bewegungskegel visualisieren dir Reichweite einer Einheit an Abhängigkeit von ihrer Maximalgeschwindigkeit. Sie ermöglichen eine Aussage darüber, welche Meldungen, die zu unterschiedlichen Zeitpunkten gemacht wurden, wahrscheinlich zu ein und derselben Einheit gehören. Gesicherte Informationen können jedoch nur darüber gewonnen werden, ob zwei Meldungen zu unterschiedlichen Einheiten gehören. Dies ist der Fall, wenn sich die eine außerhalb des Kegels der anderen Einheit befindet. Für weitergehende Informationen sei auf Abschnitt \ref{sec:Bewegungskegel} und \ref{ch:bewegungskegel} verwiesen. [IMG]

\subsubsection{Zugehörigkeitslinien}
\label{sec:Zugehoerigkeitslinien}
Die Bewegungskegel haben den Nachteil, dass die Einblendung mehrerer schnell die Übersichtlichkeit einschränkt. Aus diesem Grunde kann man alternativ mit Linien arbeiten. Rechnerisch wird von jedem Datum aus bestimmt, welches andere Datum sich im Kegel befindet. Wie diese Berechnung erfolgt, ist in Abschnitt \ref{ch:bewegungskegel} beschrieben. Alle Daten, die sich rechnerisch im Kegel befinden, werden nun mit dem Datum, das theoretisch an der Spitze des Kegels steht, verbunden. Der Kegel muss nun nicht mehr eingeblendet werden, die wahrscheinliche Zusammengehörigkeit ergibt sich aus den Linien. So können die Bewegungen von Objekten aus einer statischen Ansicht nachvollzogen werden. [IMG]