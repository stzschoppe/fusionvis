%----------------------------------------------------------------%
% theorie.tex																			       %
%----------------------------------------------------------------%

\chapter{Multisensorische Daten und ihre Visualisierung}
\label{ch:theorie}

In diesem Kapitel soll zuerst der Zusammenhang zwischen dem Thema dieser Arbeit und den dafür relevanten Theoretischen Grundlagen dargelegt werden. Darauf folgend sollen Möglichkeiten der Datenvisualisierung aufgezeigt. Einige davon sind in der prototypischen Implementierung umgesetzt, andere wurden nicht aufgenommen. Die gründe dafür sollen an geeigneter Stelle dargelegt werden.

\section{Theoretische Einordnung}
\label{sec:TheoretischeEinordnung}
In diesem Abschnitt soll die  theoretische Einordnung der Arbeit erfolgen. An erster Stelle steht dabei die Erläuterung multisensorischer Daten anhand eines einfachen Beispiels. Anschließend soll mit dessen Hilfe der Begriff \emph{Multisensor Data Fusion} definiert und der praktische Teil dieser Arbeit in den theoretischen Kontext eingeordnet werden.

\subsection{Multisensorische Daten}
\label{sec:EigenschaftenVonMultisensorischenDaten}
Der Begriff der \emph{multisensorischen Daten} existiert in der Literatur nicht losgelöst. Interessant ist er nur in Verbindung der Fusion von Daten. Trotzdem soll an dieser Stelle eine kurze begriffliche Betrachtung stehen.

\label{beispiel}
Ein kleines Beispiel verdeutlicht sehr gut, worum es hier geht: Man stelle sich einen Tisch vor, auf dem zwei brennende Kerzen stehen. Davor befinden sich drei Beobachter. Jeder soll unabhängig von den anderen auf einem Blatt Papier jeden Gegenstand beschreiben, den er sieht. Bei den entstehenden Dokumenten handelt es sich um eine Form von multisensorischen Daten. Ein Datum ist dabei eine Beschreibung eines Gegenstandes. Ein Sensor ist jeweils einer der Beobachter.  Dies ist ein Ansatz, sich der Thematik zu nähern. 

Ein anderer Ansatz könnte bei selbem Aufbau mit einer Person gemacht werden. Denn der Mensch, oder besser seine Sinne liefert schon multisensorische Daten. Die Person sieht eine Lichtquelle und fühlt eine Hitzequelle. Diese beiden Beobachtungen sind die Daten, die Sensoren sind Tastsinn und Sehsinn.

Multisensorische Daten wie oben geschildert sind aber in der Theorie und Praxis nicht von Bedeutung, wenn sie für sich genommen werden. Schlüssige Informationen daraus sind nämlich nicht möglich, ohne die Eingangsdaten zu interpretieren. Dieser Vorgang, man spricht von \emph{Multisensor Data Fusion}, soll in Abschnitt [REF] erläutert werden.
\paragraph{Vorteile}
\label{sec:Vorteile}
In \cite{MDFLLINAS} werden neun Vorteile von multisensorischen Systemen (und den von ihnen gelieferten Daten) aufgezählt, die hier in Auswahl sinngemäß wiedergegeben werden sollen:

\begin{enumerate}
	\item \textbf{Robustheit:} Informationen können weiter gesammelt werden, auch wenn einer oder mehrere Sensoren keine Daten mehr liefern.

	\item \textbf{R\protect\"aumlich weitreichende Abdeckung:} Daten, die vielleicht nur von einem der vielen Sensoren gesehen werden, würden nicht entdeckt, wenn nur ein einzelner Sensor an der falschen Stelle steht.

	\item \textbf{Zeitlich weitreichende Abdeckung:} Nicht jeder Sensor steht zu jeder Zeit zur Verfügung. Bei zeitlichem Versatz und Überlappung kann eine dauerhafte Datensammlung betrieben werden.

	\item \textbf{Gesteigerte Informationssicherheit:} Wird ein Datum durch mehrere Sensoren erfasst, verringert sich die Wahrscheinlichkeit eines Messfehlers.

	\item \textbf{Erhöhte Informationsdichte:} Die Auflösung, mit der mehrer Sensoren ein gebiet abtasten können, ist höher als die Auflösung eines einzelnen Sensors.
\end{enumerate}

Diese Reihe von Vorteilen zeigt, dass die Datensammlung mit mehreren Sensoren durchaus betrieben werden sollte. Die entstehenden Daten bieten vor allem durch ihre Redundanzen  mehr und sichere Informationen als die eines einzelnen Sensors.

\paragraph{Nachteile}
\label{sec:Nachteile}
Die oben angesprochene Redundanz ist zugleich der größte Nachteil von multisensorischen Daten. Wie sich das äußert, sei noch mal an dem in Abschnitt \ref{beispiel} eingeführten Beispiel erläutert: Die schriftlich gesammelten Daten der drei Beobachter werden an eine Person weitergegeben, die sich zum Zeitpunkt der Beobachtungen an einem anderen Ort aufhielt. Diese Person soll aus den Daten schließen, was sich auf dem Tisch befand. Sie hat dabei keine Informationen, welche Daten von welchem Beobachter stammen. Ebenfalls ist unbekannt, wie viele Beobachter überhaupt beteiligt waren.

Aus den Daten könnte die auswertende Person schließen, dass sechs Kerzen auf dem Tisch befanden. Dies ist ein völlig falsches Bild und der Grund für die Fehlinterpretation ist die Redundanz der Daten, die nicht beseitigt wurde. Nur wenn Datensätze, die zu einem realen Objekt gehören, zusammengeführt werden, kann man die Vorteile von multisensorischen Daten nutzen.


 
\subsection{Multisensor Data Fusion}
\label{sec:MultisensorFusion}
\cite{fusionintroduction} \cite{multisensorDataFusion} \cite{mathfusion}

\paragraph{Begriffsbestimmung}
\label{sec:Begriffsbestimmung}

\paragraph{Fusion Level}
\label{sec:FusionLevel}

\paragraph{Einordnung der Arbeit}
\label{sec:EinordnungDerArbeit}




\section{Visualisierungsmöglichkeiten}
\label{sec:Visualisierungsmoeglichkeiten}
Im Gegensatz zur oben beschriebenen Datenfusion soll die Beseitigung von Redundanzen in dem implementierten Prototyp durch eine geschickte Visualisierung der Daten erfolgen. Beispiele dafür werden im Folgenden erläutert. Einige finden sich in der Implementierung wieder, manche können noch ergänzt werden. An manchen Stellen musste aber eine klare Abwägung getroffen werden. Konsequenz war, dass sich bestimmte Visualisierungsarten nicht oder nur bedingt eignen.
 
\subsection{Darstellung der Dimensionen}
\label{sec:DarstellungDerDimensionen}
 Eine wichtige Entscheidung bei der Visualisierung von Daten ist, in wie vielen Dimensionen die Daten dargestellt werden sollen. Ist dies festgelegt, stellt sich die Frage, welche Eigenschaft der Daten auf welche Dimension abgebildet werden soll. 
 
\subsubsection{Dreidimensionale Darstellung}
\label{sec:DreidimensionaleDarstellung}
Ziel der praktischen Arbeit ist die dreidimensionale Darstellung von Datensätzen aus einem Gefechtssimulator. Diese Art der Datenanzeige bietet die höchste Flexibilität, jedoch kommet man bei der Abbildung von Eigenschaften auf Dimensionen zu einem Problem: Datensätze, die reale Gegenstände beschreiben, haben meistens mehr als drei Eigenschaften, die sich für ihre Positionierung eignen. Im Allgemeinen wird der Ort eines Datums durch drei Koordinaten im Raum festgelegt. Zusätzlich gibt es bei Datensätzen, die eine Sichtung beschrieben, eine Zeitangabe. Diese beschreibt, wann die Sichtung stattgefunden hat. Für die dreidimensionale Darstellung müssen drei der vier ausgewählt werden.

\paragraph{Länge-Breite-Höhe}
\label{sec:LaengeBreiteHoehe}

Eine mögliche Alternative ist die Vernachlässigung der Zeit. Diese Auswahl ist für das gestellte Problem nicht zielführend, denn durch die fehlende Zeitkomponente können Redundanzen nicht erkannt werden. Sie werden sogar gefördert. Zwei Objekte zu zwei unterschiedlichen Zeiten könnten als vier Objekte interpretiert werden. Genau diese Tatsache sollte verhindert werden. Aus diesem Grund ist diese Auswahl nicht geeignet.

\paragraph{Länge-Breite-Zeit}
\label{sec:LaengeBreiteZeit}

Die andere mögliche Alternative ist die Vernachlässigung der Höhe als Positionsangabe. Zugunsten dieser kann dann die Zeit dargestellt werden. Auch hier gibt es einen Informationsverlust. Die Auswirkungen werden in Abschnitt \ref{ch:kugelkappe} beschrieben. Für das Beseitigen von Redundanzen fällt das Weglassen der Höhe im Falle eines Gefechtssimulators nur beschränkt ins Gewicht. Landeinheiten befinden sich selten übereinander, dadurch können keine zusätzlichen Redundanzen entstehen.

Die Darstellung der Zeit als dritte Dimension (in die Höhe) bietet zwei klare Vorteile. Auf der einen Seite können in einer großen dreidimensionalen Visualisierung die unterschiedlichen Momentaufnahmen einer Lage dargestellt werden. Es ist somit eine Visuelle Lageentwicklung aus einem statischen Bild ablesbar. Auf der anderen Seite kann die Bewegungsreichweite einer Einheit anhand ihrer Maximalgeschwindigkeit veranschaulicht werden. Wie das dargestellt werden kann, wird in Abschnitt \ref{sec:TheorieBewegungskegel}, \ref{sec:Bewegungskegel} und \ref{ch:bewegungskegel} erläutert.


\subsubsection{Vierdimensionale Darstellung}
\label{sec:VierdimensionaleDarstellung}
Die beiden im letzten Abschnitt aufgezeigten Auswahlmöglichkeiten für eine dreidimensionale Visualisierung haben beide den Nachteil, dass man einen Informationsverlust in Kauf nehmen muss. Eine Möglichkeit dies zu vermeiden, wäre eine vierdimensionale Darstellung. Auf der einen Seite ist die menschliche Vorstellungskraft nicht unbedingt in der Lage, eine solche Visualisierung zu verstehen. Auf der anderen Seite benötigt man schon für die dreidimensionale Darstellung mindestens eine zweidimensionale Projektionsfläche. Für die vierte Dimension müsste man mindestens eine echte 3D-Darstellung haben, dies ist ohne spezielle Technik nicht möglich und entfällt darum.

\subsubsection{Niederdimensionale  Ansätze}
\label{sec:NiederdimensionaleAnsaetze}

\subsection{Darstellung der Datensätze}
\label{ch:visualisierungDatum}

\subsubsection{Formen}
\label{sec:Formen}

\subsubsection{Visualisierung von Eigenschaften}
\label{sec:VisualisierungVonEigenschaften}

\subsection{Informationsgewinnung durch Visualisierung}
\label{sec:InformationsgewinnungDurchVisualisierung}

\subsubsection{Bewegungskegel}
\label{sec:TheorieBewegungskegel}

\subsubsection{Zugehörigkeitslinien}
\label{sec:Zugehoerigkeitslinien}
